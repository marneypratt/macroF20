---
title: "NEON HOPB Data"
author: "Marney Pratt"
date: "10/15/2020"
output: html_notebook
---

# Load Packages  

```{r setup, include=FALSE}

# load libraries 
library(tidyverse) # for readr (import data) and dplyr (manipulate data)
library(lubridate) #for dealing with dates and times
library(neonUtilities) #to download NEON data
library(padr) # time-series data preparation functions
library(zoo) ## for dealing with time series

```

# Downloading NEON Macroinvertebrate Data  

See the NEON website for more information on the [Macroinvertebrate collection Data Product](https://data.neonscience.org/data-products/DP1.20120.001) 

```{r download all NEON macroinvertebrate data, eval=FALSE, include=FALSE}

###I ran this code once and saved the output, then I turned off running this chunk

# Macroinvert Data Product ID
my_dpid <- 'DP1.20120.001'


# get all tables for these sites from the NEON API 
# Remove token=Sys.getenv("NEON_TOKEN") line if you do not have your own API token for NEON
all_tabs_inv <- neonUtilities::loadByProduct(
  dpID = my_dpid,
  site = 'HOPB',
  package = 'expanded',
  check.size = FALSE,
  token=Sys.getenv("NEON_TOKEN"))

# extract items from list and put in R env. 
all_tabs_inv %>% list2env(.GlobalEnv)


#save readme tibble as csv file
write.csv(readme_20120, "NEONinfo/NEON_metadata.csv")

#save file with code definitions
write.csv(categoricalCodes_20120, "NEONinfo/categoricalCodes.csv")


# extract location data into a separate table
HOPB_fieldData <- inv_fieldData %>%
  
# extract year and date from collectDate, add as new column
  mutate(
    year = year(collectDate), 
    date = date(collectDate)) %>% 
  
  # keep only the columns listed below
  select(siteID, 
         domainID,
         namedLocation, 
         decimalLatitude, 
         decimalLongitude, 
         elevation,
         sampleID, 
         eventID, 
         date,
         year, 
         habitatType, 
         samplerType,
         benthicArea) %>%
  
  # keep rows with unique combinations of values, 
  # i.e., no duplicate records
  distinct()

#Save this data file
write.csv(HOPB_fieldData, "NEONdata/HOPB/HOPB_fieldData.csv")


# Make the observation table.
# start with inv_taxonomyProcessed
HOPB.macro <- inv_taxonomyProcessed %>% 
  
  # select a subset of columns from
  # inv_taxonomyProcessed
  select(sampleID,
         domainID,
         siteID,
         collectDate,
         estimatedTotalCount,
         acceptedTaxonID,
         phylum, subphylum, class, subclass, order, family, subfamily, tribe, genus, 
         scientificName,
         taxonRank) %>%
  
  # Join the columns selected above with two 
  # columns from inv_fieldData (the two columns 
  # are sampleID and benthicArea)
  left_join(HOPB_fieldData %>% 
              select(sampleID, eventID, date, year, 
                     habitatType, samplerType,
                     benthicArea)) %>%

  # some new columns called 'variable_name', 
  # 'value', and 'unit', and assign values for 
  # all rows in the table.
  # variable_name and unit are both assigned the 
  # same text string for all rows. 
  mutate(inv_dens = estimatedTotalCount / benthicArea,
         inv_dens_unit = 'count per square meter') 


#import master taxa list with tolerance values and FFGs 
neon.mill.taxa <- read_csv("data/neon.mill.taxa.csv")

#select needed variables
neon.mill.taxa2 <- neon.mill.taxa %>%  
  dplyr::select(acceptedTaxonID, organism_aggr, tolerance, FFG, FFG2)

#merge NEON macro data with master taxa data
HOPB.macro <- left_join(HOPB.macro, neon.mill.taxa2, by="acceptedTaxonID")


# save macro data file for this site
write.csv(HOPB.macro, "NEONdata/HOPB/HOPB.macro.csv", 
          row.names = FALSE)



```





# Downloading NEON Periphyton, seston, and phytoplankton collection Data  

See the NEON website for more information on the [Periphyton, seston, and phytoplankton collection Data Product](https://data.neonscience.org/data-products/DP1.20166.001) 


```{r download all NEON periphyton, seston data, eval=FALSE, include=FALSE}

###I ran this code once and saved the output, then I turned off running this chunk

# Periphyton, seston, and phytoplankton collection Data Product ID
my_dpid <- 'DP1.20166.001'


# get all tables for these sites from the NEON API 
# Remove token=Sys.getenv("NEON_TOKEN") line if you do not have your own API token for NEON
all_tabs_alg <- neonUtilities::loadByProduct(
  dpID = my_dpid,
  site = 'HOPB',
  package = 'expanded',
  check.size = FALSE,
  token=Sys.getenv("NEON_TOKEN"))

# extract items from list and put in R env. 
all_tabs_alg %>% list2env(.GlobalEnv)


#save readme tibble as csv file
write.csv(readme_20166, "NEONinfo/NEON_metadata.csv")

#save file with code definitions
write.csv(categoricalCodes_20166, "NEONinfo/categoricalCodes.csv")


# extract location data into a separate table
HOPB_alg_fieldData <- alg_fieldData %>%
  
# extract year and date from collectDate, add as new column
  mutate(
    year = year(collectDate), 
    date = date(collectDate)) %>% 
  
  # keep only the columns listed below
  dplyr::select(date,
                year,
                domainID,
                siteID, 
                parentSampleID, 
                eventID,
                namedLocation, 
                decimalLatitude, 
                decimalLongitude, 
                elevation,
                habitatType, 
                algalSampleType,
                samplerType,
                benthicArea,
                substratumSizeClass) %>% 
  dplyr::rename(., algSampleID = parentSampleID) %>% 
  
  # keep rows with unique combinations of values, 
  # i.e., no duplicate records
  distinct()

#Save this data file
write.csv(HOPB_alg_fieldData, "NEONdata/HOPB/HOPB_alg_fieldData.csv")


# Make the observation table.
# start with alg_taxonomyProcessed
HOPB.alg <- alg_taxonomyProcessed %>% 
  
  dplyr::rename(., algSampleID = sampleID) 

HOPB.alg <- HOPB.alg %>% 
  
  # select a subset of columns from
  # alg_taxonomyProcessed
  dplyr::select(domainID,
         siteID,
         namedLocation,
         collectDate,
         algSampleID,
         perBottleSampleVolume,
         algalParameter,
         algalParameterValue,
         acceptedTaxonID,
         division, class, order, family, genus, 
         specificEpithet, infraspecificEpithet,
         scientificName,
         taxonRank) %>%
  
  # Join the columns selected above with  
  # columns from alg_fieldData 
  left_join(HOPB_alg_fieldData %>% 
              dplyr::select(algSampleID, eventID, date, year, 
                     habitatType, algalSampleType,samplerType,
                     benthicArea, substratumSizeClass)) %>%

  # some new columns called 'variable_name', 
  # 'value', and 'unit', and assign values for 
  # all rows in the table.
  # variable_name and unit are both assigned the 
  # same text string for all rows. 
  mutate(alg_dens = algalParameterValue / benthicArea,
         alg_dens_unit = 'count or biovolume per square meter') 


# make master algal taxa list
HOPB.alg.taxa <- HOPB.alg %>% 
  dplyr::select(9:18) %>% 
  distinct()
  
# save master algal taxa list
write.csv(HOPB.alg.taxa, "NEONdata/HOPB/HOPB.alg.taxa.csv", 
          row.names = FALSE)

# remove taxonomy to simplify data file
HOPB.alg <- HOPB.alg %>% 
  dplyr::select(-(9:18))

# save algae data file for this site
write.csv(HOPB.alg, "NEONdata/HOPB/HOPB.alg.csv", 
          row.names = FALSE)



```



# Download Aquatic Instrument Data  

This webpage is helpful for downloading Aquatic Instrument System Data:
[Download and work with NEON Aquatic Instrument Data](https://www.neonscience.org/explore-neon-ais-data)


### product IDs
  water quality: DP1.20288.001
  air temperature: DP1.00002.001
  relative humidity: DP1.00098.001
  PAR at water surface:  DP1.20042.001
  Precipitation: DP1.00006.001
  Gage height: DP1.20267.001  
  
  
  
  
## Download Water Quality Data Product  

See the NEON website for more information on the [Water Quality Data Product](https://data.neonscience.org/data-products/DP1.20288.001)  


```{r download NEON water quality data, eval=FALSE, include=FALSE}

###I ran this code once and saved the output, then I turned off running this chunk

# Water quality Data Product ID
my_dpid <- 'DP1.20288.001'


# download data from the NEON API 
# Remove token=Sys.getenv("NEON_TOKEN") line if you do not have your own API token for NEON
waq <- neonUtilities::loadByProduct(
  dpID = my_dpid,
  site = "HOPB",
  package = 'expanded',
  check.size = FALSE,
  token=Sys.getenv("NEON_TOKEN"))

# extract items from list and put in R env. 
waq %>% list2env(.GlobalEnv)

write.csv(variables_20288, "NEONinfo/waq.vars.csv", 
          row.names = FALSE)

write.csv(readme_20288, "NEONinfo/waq.readme.csv", 
          row.names = FALSE)


waq_sum <- waq_instantaneous %>%
                dplyr::select(1:6,
                              specificConductance,
                              dissolvedOxygen,
                              dissolvedOxygenSaturation,
                              pH,
                              chlorophyll,
                              turbidity,
                              fDOM) %>%
                dplyr::mutate(date = date(startDateTime)) %>%
                group_by(domainID, siteID, horizontalPosition, date) %>%
                dplyr::summarize(
                      mean.SpCond = mean(specificConductance, na.rm = TRUE),
                      median.SpCond = median(specificConductance, na.rm = TRUE),
                      mean.DO = mean(dissolvedOxygen, na.rm = TRUE),
                      median.DO = median(dissolvedOxygen, na.rm = TRUE),
                      mean.DOsat = mean(dissolvedOxygenSaturation, na.rm = TRUE),
                      median.DOsat = median(dissolvedOxygenSaturation, na.rm = TRUE),
                      mean.pH = mean(pH, na.rm = TRUE),
                      median.pH = median(pH, na.rm = TRUE),
                      mean.chl = mean(chlorophyll, na.rm = TRUE),
                      median.chl = median(chlorophyll, na.rm = TRUE),
                      mean.turb = mean(turbidity, na.rm = TRUE),
                      median.turb = median(turbidity, na.rm = TRUE),
                      mean.fDOM = mean(fDOM, na.rm = TRUE),
                      median.fDOM = median(fDOM, na.rm = TRUE)
                                  )

write.csv(waq_sum, "NEONdata/HOPB/HOPB.waq.csv", 
          row.names = FALSE)

```


## Download Temperature (PRT) in Surface Water Data Product  

See the NEON website for more information on the [Temperature (PRT) in Surface Water Data Product](https://data.neonscience.org/data-products/DP1.20053.001)  


```{r download NEON water temp data, eval=FALSE, include=FALSE}

###I ran this code once and saved the output, then I turned off running this chunk

# Water temperature Data Product ID
my_dpid <- 'DP1.20053.001'


# download data from the NEON API 
# Remove token=Sys.getenv("NEON_TOKEN") line if you do not have your own API token for NEON
wTemp <- neonUtilities::loadByProduct(
  dpID = my_dpid,
  site = "HOPB",
  package = 'expanded',
  check.size = FALSE,
  token=Sys.getenv("NEON_TOKEN"))

# extract items from list and put in R env. 
wTemp %>% list2env(.GlobalEnv)

write.csv(variables_20053, "NEONinfo/wTemp.vars.csv", 
          row.names = FALSE)

write.csv(readme_20053, "NEONinfo/wTemp.readme.csv", 
          row.names = FALSE)


wTemp_sum <- TSW_5min %>%
                dplyr::select(1:7) %>%
                dplyr::mutate(date = date(startDateTime)) %>%
                group_by(domainID, siteID, horizontalPosition, date) %>%
                dplyr::summarize(
                      mean.wTemp = mean(surfWaterTempMean, na.rm = TRUE),
                      median.wTemp = median(surfWaterTempMean, na.rm = TRUE),
                                  )

write.csv(wTemp_sum, "NEONdata/HOPB/HOPB.wTemp.csv", 
          row.names = FALSE)

```


## Download the Precipitation Data Product  

See the NEON website for more information on the [Precipitation Data Product](https://data.neonscience.org/data-products/DP1.00006.001)  


```{r download NEON precipitation data, eval=FALSE, include=FALSE}

###I ran this code once and saved the output, then I turned off running this chunk


# Precipitation Data Product ID
my_dpid <- 'DP1.00006.001'


# download data from the NEON API 
# Remove token=Sys.getenv("NEON_TOKEN") line if you do not have your own API token for NEON
precip <- neonUtilities::loadByProduct(
  dpID = my_dpid,
  # many aquatic sites don't have precipitation sensors,
  # pick the nearest terrestrial site
  site = "HARV",
  package = 'expanded',
  check.size = FALSE,
  token=Sys.getenv("NEON_TOKEN"))

# extract items from list and put in R env. 
precip %>% list2env(.GlobalEnv)


write.csv(variables_00006, "NEONinfo/precip.vars.csv",
row.names = FALSE)

write.csv(readme_00006, "NEONinfo/precip.readme.csv",
row.names = FALSE)



#calculate the total precipitation for each date
precip_daily <- PRIPRE_30min %>%
                dplyr::select(1:6,
                    priPrecipBulk) %>%
                    dplyr::mutate(date = date(startDateTime),
                    year = year(startDateTime),
                    yday = yday(startDateTime)) %>%
                    group_by(domainID, siteID, date, year, yday) %>%
                    dplyr::summarize(
                    daily.precip = sum(priPrecipBulk, na.rm = TRUE)
                    )

# calculate the total monthly precipitation 
# by summing the daily precipitation for 30 days before each date
# note that I relabeled the siteID from HARV to HOPB
# the HARV site was the closest site where precipitation was measured
precip <- precip_daily %>%
                group_by(year) %>%
                arrange(year, yday) %>%
                mutate(mon.precip = rollapply(data = daily.precip,
                width = 30,
                FUN = sum,
                align = "right",
                fill = NA,
                na.rm = TRUE)) %>% 
          mutate(siteID = "HOPB")



write.csv(precip, "NEONdata/HOPB/HOPB.precip.csv",
row.names = FALSE)


```



## Download the Single Aspirated Air Temperature Data Product

See the NEON website for more information on the [Single Aspirated Air Temperature Data Product](https://data.neonscience.org/data-products/DP1.00002.001)



```{r download NEON air temperature data, eval=FALSE, include=FALSE}

###I ran this code once and saved the output, then I turned off running this chunk


# Air Temp Data Product ID
my_dpid <- 'DP1.00002.001'

# get all tables for these sites from the NEON API
# Remove token=Sys.getenv("NEON_TOKEN") line if you do not have your own API token for NEON
aTemp <- neonUtilities::loadByProduct(
          dpID = my_dpid,
          site = "HOPB",
          package = 'expanded',
          check.size = FALSE,
          token=Sys.getenv("NEON_TOKEN"))


# extract items from list and put in R env.
aTemp %>% list2env(.GlobalEnv)


write.csv(variables_00002, "NEONinfo/aTemp.vars.csv",
row.names = FALSE)

write.csv(readme_00002, "NEONinfo/aTemp.readme.csv",
row.names = FALSE)



#calculate the average air temp for each date
aTemp_daily <- SAAT_1min %>%
                dplyr::select(1:6,
                    tempSingleMean) %>%
                dplyr::mutate(date = date(startDateTime),
                    year = year(startDateTime),
                    yday = yday(startDateTime)) %>%
                    group_by(domainID, siteID, date, year, yday) %>%
                dplyr::summarize(mean.aTemp = mean(tempSingleMean, na.rm = TRUE)) %>% 
                mutate(pos.aTemp = replace(mean.aTemp, which(mean.aTemp<0), 0))
                

# calculate the aggregated degree days (ADD)
# by summing the ave temp for 30 days before each date
ADD <- aTemp_daily %>%
                group_by(year) %>%
                arrange(year, yday) %>%
                mutate(mon.ADD = rollapply(data = pos.aTemp,
                width = 30,
                FUN = sum,
                align = "right",
                fill = NA,
                na.rm = FALSE))


write.csv(ADD, "NEONdata/HOPB/HOPB.ADD.csv",
row.names = FALSE)

```



## Download the Photosynthetically active radiation at water surface Data Product

See the NEON website for more information on the [Photosynthetically active radiation at water surface Data Product](https://data.neonscience.org/data-products/DP1.20042.001)



```{r download NEON PAR data, eval=FALSE, include=FALSE}

###I ran this code once and saved the output, then I turned off running this chunk


# PAR Data Product ID
my_dpid <- 'DP1.20042.001'

# get all tables for these sites from the NEON API
# Remove token=Sys.getenv("NEON_TOKEN") line if you do not have your own API token for NEON
parws <- neonUtilities::loadByProduct(
          dpID = my_dpid,
          site = "HOPB",
          package = 'expanded',
          check.size = FALSE,
          token=Sys.getenv("NEON_TOKEN"))


# extract items from list and put in R env.
parws %>% list2env(.GlobalEnv)


write.csv(variables_20042, "NEONinfo/parws.vars.csv",
row.names = FALSE)

write.csv(readme_20042, "NEONinfo/parws.readme.csv",
row.names = FALSE)



#calculate the average PAR for each date
parws_daily <- PARWS_1min %>%
                dplyr::select(1:7) %>%
                dplyr::mutate(date = date(startDateTime)) %>%
                group_by(domainID, siteID, horizontalPosition, date) %>%
                dplyr::summarize(
                      mean.parws = mean(PARMean, na.rm = TRUE),
                      median.parws = median(PARMean, na.rm = TRUE),
                                  )

write.csv(parws_daily, "NEONdata/HOPB/HOPB.parws.csv", 
          row.names = FALSE)

```


# Import Data  

After running the above chunks once to download all the data, then just import all the resulting data files running the code below  

```{r Import prepped HOPB.macro.csv file, include=FALSE}

# this will import the NEON macro data for this one site
HOPB.macro <- read_csv("NEONdata/HOPB/HOPB.macro.csv")
                                      

```

```{r Import prepped HOPB.alg.csv file, include=FALSE}

# this will import the NEON Periphyton, seston, and phytoplankton data for this one site
HOPB.alg <- read_csv("NEONdata/HOPB/HOPB.alg.csv")

```


```{r import and join environmental variables, include=FALSE}

#import water quality data
HOPB.waq <- read_csv("NEONdata/HOPB/HOPB.waq.csv",
                     col_types = cols(.default = "d", 
                                      date = "D",
                                      domainID = "c",
                                      siteID = "c")
                                      )



#import surface water temperature data
HOPB.wTemp <- read_csv("NEONdata/HOPB/HOPB.wTemp.csv",
                     col_types = cols(.default = "d", 
                                      date = "D",
                                      domainID = "c",
                                      siteID = "c")
                                      )


#import precipitation data
HOPB.precip<- read_csv("NEONdata/HOPB/HOPB.precip.csv",
                     col_types = cols(.default = "d", 
                                      date = "D",
                                      domainID = "c",
                                      siteID = "c")
                                      )



#import aggregated degree days (ADD) data
HOPB.ADD<- read_csv("NEONdata/HOPB/HOPB.ADD.csv",
                     col_types = cols(.default = "d", 
                                      date = "D",
                                      domainID = "c",
                                      siteID = "c")
                                      )


#import PAR at water surface data
HOPB.parws <- read_csv("NEONdata/HOPB/HOPB.parws.csv",
                     col_types = cols(.default = "d", 
                                      date = "D",
                                      domainID = "c",
                                      siteID = "c")
                                      )




```


## Join NEON Macroinvertebrate Data and Environmental Variables

```{r join NEON macros and environmental vars for HOPB, include=FALSE}


# select columns needed
HOPB.ADD.r <- HOPB.ADD %>% dplyr::select(date, mon.ADD)

HOPB.precip.r <- HOPB.precip %>% dplyr::select(date, mon.precip)

# join precip and ADD to macro data
HOPB.macro <- left_join(HOPB.macro, HOPB.ADD.r, by = "date") %>% 
              left_join( ., HOPB.precip.r, by = "date")



#join water quality, water temperature, and PAR data
HOPB.waq2 <- left_join(HOPB.waq, HOPB.wTemp) %>% 
            left_join( ., HOPB.parws)

#filter for upstream sensor sets (note - no fDOM)
HOPB.waq.up <- HOPB.waq2 %>% 
        dplyr::filter(horizontalPosition == 101 | horizontalPosition == 111) %>% 
        group_by(domainID, siteID, date) %>% 
        dplyr::summarize(
                      mean.SpCond = mean(mean.SpCond, na.rm = TRUE),
                      median.SpCond = mean(median.SpCond, na.rm = TRUE),
                      mean.DO = mean(mean.DO, na.rm = TRUE),
                      median.DO = mean(median.DO, na.rm = TRUE),
                      mean.DOsat = mean(mean.DOsat, na.rm = TRUE),
                      median.DOsat = mean(median.DOsat, na.rm = TRUE),
                      mean.pH = mean(mean.pH, na.rm = TRUE),
                      median.pH = mean(median.pH, na.rm = TRUE),
                      mean.chl = mean(mean.chl, na.rm = TRUE),
                      median.chl = mean(median.chl, na.rm = TRUE),
                      mean.turb = mean(mean.turb, na.rm = TRUE),
                      median.turb = mean(median.turb, na.rm = TRUE),
                      mean.fDOM = mean(mean.fDOM, na.rm = TRUE),
                      median.fDOM = mean(median.fDOM, na.rm = TRUE),
                      mean.wTemp = mean(mean.wTemp, na.rm = TRUE),
                      median.wTemp = mean(median.wTemp, na.rm = TRUE),
                      mean.parws = mean(mean.parws, na.rm = TRUE),
                      median.parws = mean(median.parws, na.rm = TRUE))

#filter for downstream sensor sets 
HOPB.waq.down <- HOPB.waq2 %>% 
        dplyr::filter(horizontalPosition == 102 | horizontalPosition == 112) %>% 
        group_by(domainID, siteID, date) %>% 
        dplyr::summarize(
                      mean.SpCond = mean(mean.SpCond, na.rm = TRUE),
                      median.SpCond = mean(median.SpCond, na.rm = TRUE),
                      mean.DO = mean(mean.DO, na.rm = TRUE),
                      median.DO = mean(median.DO, na.rm = TRUE),
                      mean.DOsat = mean(mean.DOsat, na.rm = TRUE),
                      median.DOsat = mean(median.DOsat, na.rm = TRUE),
                      mean.pH = mean(mean.pH, na.rm = TRUE),
                      median.pH = mean(median.pH, na.rm = TRUE),
                      mean.chl = mean(mean.chl, na.rm = TRUE),
                      median.chl = mean(median.chl, na.rm = TRUE),
                      mean.turb = mean(mean.turb, na.rm = TRUE),
                      median.turb = mean(median.turb, na.rm = TRUE),
                      mean.fDOM = mean(mean.fDOM, na.rm = TRUE),
                      median.fDOM = mean(median.fDOM, na.rm = TRUE),
                      mean.wTemp = mean(mean.wTemp, na.rm = TRUE),
                      median.wTemp = mean(median.wTemp, na.rm = TRUE),
                      mean.parws = mean(mean.parws, na.rm = TRUE),
                      median.parws = mean(median.parws, na.rm = TRUE))



# join upstream sensor set data to macro data
HOPB.macro.up <- left_join(HOPB.macro, HOPB.waq.up)

# save the fully merged and prepared data file
# For the metadata describing everything in the file see _____ text file included in the Project folder 

write.csv(HOPB.macro.up, "preppedData/HOPB.macro.up.csv", 
          row.names = FALSE)
  

# join downstream sensor set data to macro data
HOPB.macro.down <- left_join(HOPB.macro, HOPB.waq.down) 


# save the fully merged and prepared data file
# For the metadata describing everything in the file see _____ text file included in the Project folder 

write.csv(HOPB.macro.down, "preppedData/HOPB.macro.down.csv", 
          row.names = FALSE)


```


## Join NEON Periphyton and Seston Data and Environmental Variables

```{r join NEON algae and light vars for HOPB, include=FALSE}


#filter for upstream sensor sets (note - no fDOM)
HOPB.parws.up <- HOPB.parws %>% 
        dplyr::filter(horizontalPosition == 101 | horizontalPosition == 111) %>% 
        group_by(domainID, siteID, date) %>% 
        dplyr::summarize(
                      mean.parws = mean(mean.parws, na.rm = TRUE),
                      median.parws = mean(median.parws, na.rm = TRUE))

#filter for downstream sensor sets 
HOPB.parws.down <- HOPB.parws %>% 
        dplyr::filter(horizontalPosition == 102 | horizontalPosition == 112) %>% 
        group_by(domainID, siteID, date) %>% 
        dplyr::summarize(
                      mean.parws = mean(mean.parws, na.rm = TRUE),
                      median.parws = mean(median.parws, na.rm = TRUE))



# join upstream sensor set data to algae data
HOPB.alg.up <- left_join(HOPB.alg, HOPB.parws.up)

# save the fully merged and prepared data file
write.csv(HOPB.alg.up, "preppedData/HOPB.alg.up.csv", 
          row.names = FALSE)
  

# join downstream sensor set data to algae data
HOPB.alg.down <- left_join(HOPB.alg, HOPB.parws.down) 


# save the fully merged and prepared data file
write.csv(HOPB.alg.down, "preppedData/HOPB.alg.down.csv", 
          row.names = FALSE)


```

