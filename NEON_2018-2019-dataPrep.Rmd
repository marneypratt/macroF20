---
title: "NEON Macroinvertebrates Data"
author: "Marney Pratt"
date: "10/15/2020"
output: html_notebook
---

# Load Packages  

```{r setup, include=FALSE}

# load libraries 
library(tidyverse) # for readr (import data) and dplyr (manipulate data)
library(lubridate) #for dealing with dates and times
library(neonUtilities) #to download NEON data
library(padr) # time-series data preparation functions
library(zoo) ## for dealing with time series

```

# Downloading NEON Macroinvertebrate Data  

```{r download all NEON macroinvertebrate data, eval=FALSE, include=FALSE}

###I ran this code once and saved the output, then I turned off running this chunk

# Macroinvert Data Product ID
my_dpid <- 'DP1.20120.001'


# get all tables for these sites from the NEON API 
# Remove token=Sys.getenv("NEON_TOKEN") line if you do not have your own API token for NEON
all_tabs_inv <- neonUtilities::loadByProduct(
  dpID = my_dpid,
  site = 'all',
  package = 'expanded',
  check.size = FALSE,
  token=Sys.getenv("NEON_TOKEN"))

# extract items from list and put in R env. 
all_tabs_inv %>% list2env(.GlobalEnv)


#save readme tibble as csv file
write.csv(readme_20120, "NEONdata/NEON_metadata.csv")

#save file with code definitions
write.csv(categoricalCodes_20120, "NEONdata/categoricalCodes.csv")


```


```{r find wadeable stream sites, eval=FALSE, include=FALSE}

#Run this code to find the wadeable stream sites for 2018-2019, then change the options above so this code chunk isn't run again

# extract year from date, add it as a new column
# filter for streams in 2018-2019
inv_fieldData <- inv_fieldData %>%
  mutate(
    year = collectDate %>% 
      lubridate::as_date() %>% 
      lubridate::year(),
    month = collectDate %>% 
      lubridate::as_date() %>% 
      lubridate::month()) %>% 
  dplyr::filter(aquaticSiteType == "stream",
                year == 2018 |
                year == 2019)

# extract location data into a separate table
NEON_fieldData <- inv_fieldData %>%
  
  # keep only the columns listed below
  select(siteID, 
         domainID,
         namedLocation, 
         decimalLatitude, 
         decimalLongitude, 
         elevation) %>%
  
  # keep rows with unique combinations of values, 
  # i.e., no duplicate records
  distinct()

#Save this data file
write.csv(NEON_fieldData, "NEONdata/NEON_fieldData.csv")

```


```{r  save the macroinvertebrate data for 2018-2019, eval=FALSE, include=FALSE}

#Run this code to save the wadeable stream macro data for 2018-2019, then change the options above so this code chunk isn't run again


# Make the observation table.
# start with inv_taxonomyProcessed
neon.macro <- inv_taxonomyProcessed %>% 
  
  # select a subset of columns from
  # inv_taxonomyProcessed
  select(sampleID,
         domainID,
         siteID,
         collectDate,
         estimatedTotalCount,
         acceptedTaxonID,
         phylum, subphylum, class, subclass, order, family, subfamily, tribe, genus, 
         scientificName,
         taxonRank) %>%
  
  # Join the columns selected above with two 
  # columns from inv_fieldData (the two columns 
  # are sampleID and benthicArea)
  left_join(inv_fieldData %>% 
              select(sampleID, eventID, year, 
                     habitatType, samplerType,
                     benthicArea)) %>%
  
  # some new columns called 'variable_name', 
  # 'value', and 'unit', and assign values for 
  # all rows in the table.
  # variable_name and unit are both assigned the 
  # same text strint for all rows. 
  mutate(inv_dens = estimatedTotalCount / benthicArea,
         inv_dens_unit = 'count per square meter') %>% 

  #filter for years
  dplyr::filter(year == 2018 | year == 2019)


#import master taxa list with tolerance values and FFGs 
neon.mill.taxa <- read_csv("data/neon.mill.taxa.csv")

#merge NEON macro data with master taxa data
neon.mill.taxa2 <- neon.mill.taxa %>%  
  dplyr::select(acceptedTaxonID, organism_aggr, tolerance, FFG, FFG2)

neon.macro <- left_join(neon.macro, neon.mill.taxa2, by="acceptedTaxonID")



write.csv(NEON_fieldData, "NEONdata/neon.macro.csv", 
          row.names = FALSE)

```


## Import all NEON Macroinvertebrate Data for all Wadeable Streams

```{r Import prepped neon.macro.csv file}

# this file is the result of the above three chunks
# run the above three chunks once to create this file
# then after that, don't run the above chunks and only run this one 
# this will import the NEON macro data for wadeable streams in 2018-2019
neon.macro <- read_csv("NEONdata/neon.macro.csv")

```




# Download Aquatic Instrument Data  

This webpage is helpful for downloading Aquatic Instrument System Data:
[Download and work with NEON Aquatic Instrument Data](https://www.neonscience.org/explore-neon-ais-data)


### product IDs
  water quality: DP1.20288.001
  air temperature: DP1.00002.001
  relative humidity: DP1.00098.001
  PAR at water surface:  DP1.20042.001
  Precipitation: DP1.00006.001
  Gage height: DP1.20267.001  
  
  
  
## Download Water Quality Data Product  

See the NEON website for more information on the [Water Quality Data Product](https://data.neonscience.org/data-products/DP1.20288.001)  


```{r download NEON water quality data, eval=FALSE, include=FALSE}

###I ran this code once and saved the output, then I turned off running this chunk

# Water quality Data Product ID
my_dpid <- 'DP1.20288.001'


# download data from the NEON API 
# Remove token=Sys.getenv("NEON_TOKEN") line if you do not have your own API token for NEON
waq <- neonUtilities::loadByProduct(
  dpID = my_dpid,
  site = "HOPB",
  startdate = "2018-01",
  enddate = "2019-12",
  package = 'expanded',
  check.size = FALSE,
  token=Sys.getenv("NEON_TOKEN"))

# extract items from list and put in R env. 
waq %>% list2env(.GlobalEnv)

write.csv(variables_20288, "NEONdata/waq.vars.csv", 
          row.names = FALSE)

write.csv(readme_20288, "NEONdata/waq.readme.csv", 
          row.names = FALSE)


waq_sum <- waq_instantaneous %>%
                dplyr::select(1:6,
                              specificConductance,
                              dissolvedOxygen,
                              dissolvedOxygenSaturation,
                              pH,
                              chlorophyll,
                              turbidity,
                              fDOM) %>%
                dplyr::mutate(date = date(startDateTime)) %>%
                group_by(domainID, siteID, horizontalPosition, date) %>%
                dplyr::summarize(
                      mean.SpCond = mean(specificConductance, na.rm = TRUE),
                      median.SpCond = median(specificConductance, na.rm = TRUE),
                      mean.DO = mean(dissolvedOxygen, na.rm = TRUE),
                      median.DO = median(dissolvedOxygen, na.rm = TRUE),
                      mean.DOsat = mean(dissolvedOxygenSaturation, na.rm = TRUE),
                      median.DOsat = median(dissolvedOxygenSaturation, na.rm = TRUE),
                      mean.pH = mean(pH, na.rm = TRUE),
                      median.pH = median(pH, na.rm = TRUE),
                      mean.chl = mean(chlorophyll, na.rm = TRUE),
                      median.chl = median(chlorophyll, na.rm = TRUE),
                      mean.turb = mean(turbidity, na.rm = TRUE),
                      median.turb = median(turbidity, na.rm = TRUE),
                      mean.fDOM = mean(fDOM, na.rm = TRUE),
                      median.fDOM = median(fDOM, na.rm = TRUE)
                                  )

write.csv(waq_sum, "NEONdata/HOPB/HOPB.waq.csv", 
          row.names = FALSE)

```


## Download the Precipitation Data Product  

See the NEON website for more information on the [Precipitation Data Product](https://data.neonscience.org/data-products/DP1.00006.001)  


```{r download NEON precipitation data, eval=FALSE, include=FALSE}

###I ran this code once and saved the output, then I turned off running this chunk


# Precipitation Data Product ID
my_dpid <- 'DP1.00006.001'


# download data from the NEON API 
# Remove token=Sys.getenv("NEON_TOKEN") line if you do not have your own API token for NEON
precip <- neonUtilities::loadByProduct(
  dpID = my_dpid,
  # many aquatic sites don't have precipitation sensors,
  # pick the nearest terrestrial site
  site = "HARV",
  startdate = "2018-01",
  enddate = "2019-12",
  package = 'expanded',
  check.size = FALSE,
  token=Sys.getenv("NEON_TOKEN"))

# extract items from list and put in R env. 
precip %>% list2env(.GlobalEnv)


write.csv(variables_00006, "NEONdata/precip.vars.csv",
row.names = FALSE)

write.csv(readme_00006, "NEONdata/precip.readme.csv",
row.names = FALSE)





write.csv(PRIPRE_30min, "NEONdata/HOPB/HOPB.precip.csv",
row.names = FALSE)


```



## Download the Single Aspirated Air Temperature Data Product

See the NEON website for more information on the [Single Aspirated Air Temperature Data Product](https://data.neonscience.org/data-products/DP1.00002.001)



```{r download NEON air temperature data, eval=FALSE, include=FALSE}

###I ran this code once and saved the output, then I turned off running this chunk


# Air Temp Data Product ID
my_dpid <- 'DP1.00002.001'

# get all tables for these sites from the NEON API
# Remove token=Sys.getenv("NEON_TOKEN") line if you do not have your own API token for NEON
aTemp <- neonUtilities::loadByProduct(
          dpID = my_dpid,
          site = "HOPB",
          startdate = "2018-01",
          enddate = "2019-12",
          package = 'expanded',
          check.size = FALSE,
          token=Sys.getenv("NEON_TOKEN"))


# extract items from list and put in R env.
aTemp %>% list2env(.GlobalEnv)


write.csv(variables_00002, "NEONdata/aTemp.vars.csv",
row.names = FALSE)

write.csv(readme_00002, "NEONdata/aTemp.readme.csv",
row.names = FALSE)



#calculate the average air temp for each date
aTemp_daily <- SAAT_1min %>%
                dplyr::select(1:6,
                    tempSingleMean) %>%
                    dplyr::mutate(date = date(startDateTime),
                    year = year(startDateTime),
                    yday = yday(startDateTime)) %>%
                    group_by(domainID, siteID, horizontalPosition, date, year, yday) %>%
                    dplyr::summarize(
                    mean.aTemp = mean(tempSingleMean, na.rm = TRUE)
                    )

# calculate the aggregated degree days (ADD)
# by summing the ave temp for 30 days before each date
ADD <- aTemp_daily %>%
                group_by(year) %>%
                arrange(year, yday) %>%
                mutate(mon.ADD = rollapply(data = mean.aTemp,
                width = 30,
                FUN = sum,
                align = "right",
                fill = NA,
                na.rm = TRUE))


```



## Import Environmental Variables  

After running the above chunks once to download all the environmental variables, then just import all the resulting data files running the code below  

```{r import environmental variables}

#import water quality data
HOPB.waq <- read_csv("NEONdata/HOPB/HOPB.waq.csv")




```




